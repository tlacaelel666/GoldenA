# Tests para GoldenA

Este directorio contiene los tests automatizados para el proyecto GoldenA.

## ğŸ“‹ Requisitos

Los tests requieren las siguientes dependencias (ya incluidas en `requirements.txt`):

- pytest >= 7.0.0
- numpy >= 1.23.0
- plotly >= 5.0.0

## ğŸš€ EjecuciÃ³n de Tests

### Ejecutar todos los tests

```bash
pytest
```

### Ejecutar tests con mÃ¡s detalle

```bash
pytest -v
```

### Ejecutar un archivo especÃ­fico

```bash
pytest tests/test_analisis_aureo.py
```

### Ejecutar una clase especÃ­fica de tests

```bash
pytest tests/test_analisis_aureo.py::TestConstantesAureas
```

### Ejecutar un test especÃ­fico

```bash
pytest tests/test_analisis_aureo.py::TestConstantesAureas::test_phi_value
```

### Ejecutar tests con cobertura (si tienes pytest-cov instalado)

```bash
pytest --cov=. --cov-report=html
```

## ğŸ·ï¸ Markers (Etiquetas)

Los tests estÃ¡n organizados con los siguientes markers:

- `@pytest.mark.slow`: Tests que tardan mÃ¡s tiempo
- `@pytest.mark.unit`: Tests unitarios
- `@pytest.mark.integration`: Tests de integraciÃ³n

### Ejecutar solo tests rÃ¡pidos (excluir tests lentos)

```bash
pytest -m "not slow"
```

### Ejecutar solo tests lentos

```bash
pytest -m slow
```

## ğŸ“ Estructura de Tests

### `test_analisis_aureo.py`

Tests para el mÃ³dulo `analisis_aureo.py`:

#### `TestConstantesAureas`

- âœ“ VerificaciÃ³n del valor de PHI (proporciÃ³n Ã¡urea)
- âœ“ VerificaciÃ³n de la propiedad fundamental: PHIÂ² = PHI + 1

#### `TestCalculosAureos`

- âœ“ Paridad para valores pares (cos(n*Ï€) = 1)
- âœ“ Paridad para valores impares (cos(n*Ï€) = -1)
- âœ“ Rango de la fase cuasiperiÃ³dica [-1, 1]
- âœ“ CÃ¡lculo de dimensiÃ³n (producto de paridad y cuasiperiÃ³dica)
- âœ“ CÃ¡lculo del valor ponderado

#### `TestProbabilidadTeorica`

- âœ“ Rango de probabilidad teÃ³rica [0, 1]
- âœ“ Valor de probabilidad para n=0

#### `TestEjecucionAnalisis`

- âœ“ EjecuciÃ³n con valores por defecto
- âœ“ EjecuciÃ³n con valores personalizados de n
- âœ“ Manejo de entradas invÃ¡lidas

#### `TestDatosExperimentales`

- âœ“ ValidaciÃ³n de longitud de datos experimentales
- âœ“ VerificaciÃ³n de rango de probabilidades [0, 1]

#### `TestIntegracionNumerica`

- âœ“ Consistencia de tamaÃ±os de arrays
- âœ“ Ausencia de valores NaN

#### `TestPerformance`

- âœ“ Rendimiento con valores grandes de n (n=10,000)

## ğŸ“Š Resultados

Estado actual: **17 tests pasando** âœ…

## ğŸ› ï¸ Agregar Nuevos Tests

Para agregar nuevos tests:

1. Crea una nueva clase de test heredando de una clase base (opcional)
2. Nombra los mÃ©todos comenzando con `test_`
3. Usa `assert` para las verificaciones
4. AÃ±ade docstrings descriptivos

Ejemplo:

```python
class TestNuevaFuncionalidad:
    """Tests para nueva funcionalidad."""
    
    def test_algo_especifico(self):
        """Verifica comportamiento especÃ­fico."""
        resultado = mi_funcion()
        assert resultado == esperado, "Mensaje de error"
```

## ğŸ“š Recursos

- [DocumentaciÃ³n de pytest](https://docs.pytest.org/)
- [Mejores prÃ¡cticas de testing](https://docs.pytest.org/en/stable/goodpractices.html)
- [Fixtures en pytest](https://docs.pytest.org/en/stable/fixture.html)

## ğŸ› Debugging

Para ejecutar tests con mÃ¡s informaciÃ³n de debug:

```bash
pytest -vv --tb=long
```

Para ejecutar con pdb (debugger interactivo) al fallar:

```bash
pytest --pdb
```

Para ver print statements durante la ejecuciÃ³n:

```bash
pytest -s
```
